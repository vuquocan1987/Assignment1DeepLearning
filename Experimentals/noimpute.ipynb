{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1:-0.294118</td>\n",
       "      <td>2:0.487437</td>\n",
       "      <td>3:0.180328</td>\n",
       "      <td>4:-0.292929</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:0.00149028</td>\n",
       "      <td>7:-0.53117</td>\n",
       "      <td>8:-0.0333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1:-0.882353</td>\n",
       "      <td>2:-0.145729</td>\n",
       "      <td>3:0.0819672</td>\n",
       "      <td>4:-0.414141</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:-0.207153</td>\n",
       "      <td>7:-0.766866</td>\n",
       "      <td>8:-0.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>1:-0.0588235</td>\n",
       "      <td>2:0.839196</td>\n",
       "      <td>3:0.0491803</td>\n",
       "      <td>4:-1</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:-0.305514</td>\n",
       "      <td>7:-0.492741</td>\n",
       "      <td>8:-0.633333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1:-0.882353</td>\n",
       "      <td>2:-0.105528</td>\n",
       "      <td>3:0.0819672</td>\n",
       "      <td>4:-0.535354</td>\n",
       "      <td>5:-0.777778</td>\n",
       "      <td>6:-0.162444</td>\n",
       "      <td>7:-0.923997</td>\n",
       "      <td>8:-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>1:-1</td>\n",
       "      <td>2:0.376884</td>\n",
       "      <td>3:-0.344262</td>\n",
       "      <td>4:-0.292929</td>\n",
       "      <td>5:-0.602837</td>\n",
       "      <td>6:0.28465</td>\n",
       "      <td>7:0.887276</td>\n",
       "      <td>8:-0.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0             1            2            3            4            5   \n",
       "0 -1   1:-0.294118   2:0.487437   3:0.180328  4:-0.292929         5:-1  \\\n",
       "1  1   1:-0.882353  2:-0.145729  3:0.0819672  4:-0.414141         5:-1   \n",
       "2 -1  1:-0.0588235   2:0.839196  3:0.0491803         4:-1         5:-1   \n",
       "3  1   1:-0.882353  2:-0.105528  3:0.0819672  4:-0.535354  5:-0.777778   \n",
       "4 -1          1:-1   2:0.376884  3:-0.344262  4:-0.292929  5:-0.602837   \n",
       "\n",
       "              6            7             8   9  \n",
       "0  6:0.00149028   7:-0.53117  8:-0.0333333 NaN  \n",
       "1   6:-0.207153  7:-0.766866   8:-0.666667 NaN  \n",
       "2   6:-0.305514  7:-0.492741   8:-0.633333 NaN  \n",
       "3   6:-0.162444  7:-0.923997          8:-1 NaN  \n",
       "4     6:0.28465   7:0.887276        8:-0.6 NaN  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the diabete file and build a MLP model to predict the outcome of the diabete\n",
    "import pandas as pd\n",
    "data = pd.read_csv('diabetes.txt', sep=' ', header=None)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>-0.030303</td>\n",
       "      <td>-0.574468</td>\n",
       "      <td>-0.019374</td>\n",
       "      <td>-0.920581</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.764706</td>\n",
       "      <td>0.226131</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.096870</td>\n",
       "      <td>-0.776260</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>-0.411765</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.735225</td>\n",
       "      <td>-0.219076</td>\n",
       "      <td>-0.857387</td>\n",
       "      <td>-0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>0.266332</td>\n",
       "      <td>-0.016393</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.102832</td>\n",
       "      <td>-0.768574</td>\n",
       "      <td>-0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.065327</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.373737</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.093890</td>\n",
       "      <td>-0.797609</td>\n",
       "      <td>-0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7   \n",
       "0   -0.294118  0.487437  0.180328 -0.292929 -1.000000  0.001490 -0.531170  \\\n",
       "1   -0.882353 -0.145729  0.081967 -0.414141 -1.000000 -0.207153 -0.766866   \n",
       "2   -0.058824  0.839196  0.049180 -1.000000 -1.000000 -0.305514 -0.492741   \n",
       "3   -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4   -1.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  0.176471  0.015075  0.245902 -0.030303 -0.574468 -0.019374 -0.920581   \n",
       "764 -0.764706  0.226131  0.147541 -0.454545 -1.000000  0.096870 -0.776260   \n",
       "765 -0.411765  0.216080  0.180328 -0.535354 -0.735225 -0.219076 -0.857387   \n",
       "766 -0.882353  0.266332 -0.016393 -1.000000 -1.000000 -0.102832 -0.768574   \n",
       "767 -0.882353 -0.065327  0.147541 -0.373737 -1.000000 -0.093890 -0.797609   \n",
       "\n",
       "            8  \n",
       "0   -0.033333  \n",
       "1   -0.666667  \n",
       "2   -0.633333  \n",
       "3   -1.000000  \n",
       "4   -0.600000  \n",
       "..        ...  \n",
       "763  0.400000  \n",
       "764 -0.800000  \n",
       "765 -0.700000  \n",
       "766 -0.133333  \n",
       "767 -0.933333  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from column 1 to 8 are the features, 0 are labels, splits the columns from 1 to 8 and keep second value\n",
    "X = data.iloc[:, 1:9]\n",
    "# split the columns from 0 to 7 and keep second value, convert to float\n",
    "X = X.apply(lambda x: x.str.split(':').str[1].astype(float))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values with the mean of the column\n",
    "import numpy as np\n",
    "X = X.fillna(X.mean())\n",
    "Y = data.iloc[:, 0].astype(float)\n",
    "Y = (Y + 1)//2\n",
    "Y\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MLP model using Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# the output is -1 or 1, so the activation function is sigmoid\n",
    "# build a MLP model\n",
    "# \n",
    "def create_model():\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(20, activation='relu', input_shape=[8]),\n",
    "        layers.Dense(20, activation='relu'),\n",
    "        layers.Dense(20, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,dev,test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, train_size=0.8, random_state=42)\n",
    "X_dev, X_test, Y_dev, Y_test = train_test_split(X_temp, Y_temp, train_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 24ms/step - loss: 0.6806 - accuracy: 0.6091 - val_loss: 0.6551 - val_accuracy: 0.7532\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6474 - accuracy: 0.7150 - val_loss: 0.6256 - val_accuracy: 0.7143\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6203 - accuracy: 0.7166 - val_loss: 0.5962 - val_accuracy: 0.7273\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5930 - accuracy: 0.7166 - val_loss: 0.5721 - val_accuracy: 0.7013\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5680 - accuracy: 0.7231 - val_loss: 0.5505 - val_accuracy: 0.7403\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5443 - accuracy: 0.7362 - val_loss: 0.5355 - val_accuracy: 0.7403\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5264 - accuracy: 0.7459 - val_loss: 0.5232 - val_accuracy: 0.7532\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.7508 - val_loss: 0.5141 - val_accuracy: 0.7792\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4981 - accuracy: 0.7524 - val_loss: 0.5063 - val_accuracy: 0.7922\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.7524 - val_loss: 0.5006 - val_accuracy: 0.7922\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.7573 - val_loss: 0.4992 - val_accuracy: 0.7662\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.7638 - val_loss: 0.4944 - val_accuracy: 0.8052\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.7736 - val_loss: 0.4929 - val_accuracy: 0.8052\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7687 - val_loss: 0.4938 - val_accuracy: 0.7922\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.7818 - val_loss: 0.4929 - val_accuracy: 0.8052\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.7704 - val_loss: 0.4945 - val_accuracy: 0.7922\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7736 - val_loss: 0.5064 - val_accuracy: 0.7662\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.7834 - val_loss: 0.4950 - val_accuracy: 0.8052\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7752 - val_loss: 0.5044 - val_accuracy: 0.7662\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4573 - accuracy: 0.7687 - val_loss: 0.4957 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.7769 - val_loss: 0.5042 - val_accuracy: 0.7792\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.7818 - val_loss: 0.4985 - val_accuracy: 0.7792\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.7883 - val_loss: 0.5048 - val_accuracy: 0.7792\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4479 - accuracy: 0.7850 - val_loss: 0.5059 - val_accuracy: 0.7792\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4467 - accuracy: 0.7801 - val_loss: 0.5115 - val_accuracy: 0.7792\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4646 - accuracy: 0.7662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4646388590335846, 0.7662337422370911]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_dev, Y_dev), callbacks=[early_stopping])\n",
    "model.evaluate(X_test, Y_test)\n",
    "# model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/anvu/Workspace/Master/DeepLearningFoundation/Assignment1.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anvu/Workspace/Master/DeepLearningFoundation/Assignment1.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m kfold\u001b[39m.\u001b[39msplit(X, Y):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anvu/Workspace/Master/DeepLearningFoundation/Assignment1.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model \u001b[39m=\u001b[39m create_model()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anvu/Workspace/Master/DeepLearningFoundation/Assignment1.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X[train], Y[train], epochs\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anvu/Workspace/Master/DeepLearningFoundation/Assignment1.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X[test], Y[test], verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anvu/Workspace/Master/DeepLearningFoundation/Assignment1.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mmetrics_names[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mscores[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py:1676\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1674\u001b[0m callbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1675\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1676\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1677\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m             epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m         ):\n\u001b[1;32m   1684\u001b[0m             callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/engine/data_adapter.py:1375\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1376\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1377\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1378\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[1;32m   1380\u001b[0m )\n\u001b[1;32m   1382\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:647\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    646\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 647\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    648\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    649\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1160\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1126\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1125\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1127\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = create_model()\n",
    "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0, callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(f\"{model.metrics_names[1]}: {scores[1]*100:.2f}%\")\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(f\"{np.mean(cvscores):.2f}% (+/- {np.std(cvscores):.2f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
